#include "bytecode-interpreter.h"
#include "src/trace.h"
#include "src/os.h"

#include <algorithm>
#include <cmath>
#include <map>
#include <cassert>
#include <climits>

#include <Zydis/Zydis.h>

namespace lavascript {
namespace interpreter{

inline void SetValueFlag( Value* v , std::uint32_t flag ) {
  v->raw_ = static_cast<std::uint64_t>(flag) << 32;
}

inline std::uint32_t GetValueFlag( const Value& v ) {
  return static_cast<std::uint32_t>(v.raw_ >>32);
}

namespace {

// Used in dynasm library
int ResolveExternAddress( void**,unsigned char*,int,int );

// Workaround for ODR
#include "dep/dynasm/dasm_proto.h"

#define DASM_EXTERN_FUNC(a,b,c,d) ResolveExternAddress((void**)a,b,c,d)
#include "dep/dynasm/dasm_x86.h"

// -------------------------------------------------------------
// BuildContext
//
// Build phase context, used to *generate* templated interpreter
// -------------------------------------------------------------
struct BuildContext {
  dasm_State* dasm_ctx;
  int tag;

  BuildContext():
    dasm_ctx(NULL),
    tag(0)
  {}

  ~BuildContext() {
    if(dasm_ctx) dasm_free(&dasm_ctx);
  }
};


// Shut the GCC's mouth fucked up
template< typename T >
int HorribleCast( T* ptr ) {
  std::uint64_t iptr = reinterpret_cast<std::uint64_t>(ptr);
  int ret = static_cast<int>(iptr);
  lava_verify(reinterpret_cast<T*>(ret) == ptr);
  return ret;
}

// --------------------------------------------------------------
// Runtime
//
// Used in the interpretation phase for the interpreter
// --------------------------------------------------------------
struct Runtime {
  // TODO:: This is for test purpose , no going into production
  Prototype** cur;
  Script** script;
  Object** global;
  Value ret;
  std::string* error;
  std::uint64_t stack[1024];

  Runtime( const Handle<Script>& script , const Handle<Object>& glb , std::string* err ):
    cur     (script->main().ref()),
    script  (script.ref()),
    global  (glb.ref()),
    ret     (),
    error   (err),
    stack   ()
  {}
};

static_assert( std::is_standard_layout<Runtime>::value );

struct RuntimeLayout {
  static const std::uint32_t kRetOffset = offsetof(Runtime,ret);
};

// prototype for the interpreter's main
//                    runtime  proto     stk    pc    dispatch
typedef bool (*Main)(Runtime*,Prototype**,void*,void*,void*);

// ------------------------------------------------------------------
// Helper function/macros to register its literal name into a global
// table to help resolve the function's address during assembly link
// phase
// ------------------------------------------------------------------
typedef std::map<std::string,void*> ExternSymbolTable;

ExternSymbolTable* GetExternSymbolTable() {
  static ExternSymbolTable kTable;
  return &kTable;
}

// Macro to register a external function's symbol name into global table
#define INTERPRETER_REGISTER_EXTERN_SYMBOL(XX)                               \
  struct XX##_Registry {                                                     \
    XX##_Registry() {                                                        \
      ExternSymbolTable* table = GetExternSymbolTable();                     \
      table->insert(std::make_pair(#XX,reinterpret_cast<void*>(&XX)));       \
    }                                                                        \
  };                                                                         \
  static XX##_Registry k##XX##_Registry;


// -------------------------------------------------------------------------
// Helper to set Value object to indicate special meaning
// -------------------------------------------------------------------------
#define VALUE_FAIL Value::FLAG_1



// --------------------------------------------------------------------------
// Arithmetic helper function to take care of slow path of interpretation
// --------------------------------------------------------------------------
Value InterpreterDoArithmetic( Runtime* sandbox ,
                               Value left ,  // rsi
                               Value right , // rdx
                               Bytecode bc ) {
  (void)sandbox;
  (void)left;
  (void)right;
  (void)bc;
  {
    Value r;
    SetValueFlag( &r, VALUE_FAIL );
    return r;
  }
}
INTERPRETER_REGISTER_EXTERN_SYMBOL(InterpreterDoArithmetic)

Value InterpreterPow         ( Runtime* sandbox ,
                               Value left,
                               Value right,
                               Bytecode bc ) {
  (void)sandbox;
  (void)left;
  (void)right;
  (void)bc;
  {
    Value r;
    SetValueFlag( &r, VALUE_FAIL );
    return r;
  }
}
INTERPRETER_REGISTER_EXTERN_SYMBOL(InterpreterPow)

void InterpreterModByReal    ( Runtime* sandbox , std::uint32_t* pc ) {
  (void)sandbox;
  (void)pc;
}
INTERPRETER_REGISTER_EXTERN_SYMBOL(InterpreterModByReal)

void InterpreterDivByZero    ( Runtime* sandbox , std::uint32_t* pc ) {
  (void)sandbox;
  (void)pc;
}
INTERPRETER_REGISTER_EXTERN_SYMBOL(InterpreterDivByZero)

double Pow( double a , double b ) {
  return std::pow(a,b);
}
INTERPRETER_REGISTER_EXTERN_SYMBOL(Pow)

Value InterpreterDoCompare  ( Runtime* sandbox , Value left ,
                                                 Value right,
                                                 Bytecode bc ) {
  (void)sandbox;
  (void)left;
  (void)right;
  (void)bc;
  {
    Value r;
    SetValueFlag( &r, VALUE_FAIL );
    return r;
  }
  lava_error("%s","HERE");
}
INTERPRETER_REGISTER_EXTERN_SYMBOL(InterpreterDoCompare);

/* ======================================================================
 *
 * Implementation of AssemblyIntepreter
 *
 * =====================================================================*/
|.arch x64
|.actionlist actions
|.globals GLBNAME_
|.globalnames glbnames
|.externnames extnames
|.section code,data

/* -------------------------------------------------------------------
 * 64 bits call
 *
 * Since 64 bits call cannot accept a imm value due to it is too long,
 * we need to generate different *types* of call instruction based on
 * the callsite
 * -------------------------------------------------------------------*/
inline bool CheckAddress( std::uintptr_t addr ) {
  static const std::uintptr_t k2G = 0x80000000;
  if(addr > 0 && addr < k2G)
    return true;
  else
    return false;
}

|.macro fcall,FUNC
|| if(CheckAddress(reinterpret_cast<std::uintptr_t>(FUNC))) {
|    call extern FUNC
|| } else {
||   lava_warn("%s","Function FUNC address is not in 0-2GB");
|.if 0
// I don't know whether this is faster than use rax , need profile. I see
// this one is used in MoarVM. It uses memory address to work araoud the
// address space problem. But I am kind of unsure about it since it maybe
// because MoarVM already allocate rax for other things
|9:
|.dword (std::uint32_t)((std::uintptr_t)(FUNC)),(std::uint32_t)((std::uintptr_t)((FUNC)>>32))
|    call qword[<9]
|.else
|    mov64 rax, reinterpret_cast<std::uintptr_t>(FUNC)
|    call rax
|.endif
|| }
|.endmacro

/* ---------------------------------------------------------------
 * summary of register usage                                     |
 * --------------------------------------------------------------*/
// Runtime pointer
|.define RUNTIME,               r12   // callee saved

// Current prototype's GCRef pointer
|.define PROTO,                 r13   // callee saved

// Top stack's pointer
|.define STK,                   r14   // callee saved
|.define ACCIDX,                1020
|.define ACCFIDX,               1024
|.define ACC,                   STK+ACCIDX

// Dispatch table pointer
|.define DISPATCH,              r15  // callee saved

// Bytecode array
|.define PC,                    rbp  // callee saved

// Hold the decoded unit
|.define INSTR,                 eax
|.define INSTR_OP,              al
|.define INSTR_A8,              ah
|.define INSTR_A16,             ax

/** ------------------------------------------------------------
 *
 * NOTES: A notes on movzx/movsx instruction.
 *
 *        The movzx/movsx zero out or sign out the *whole* 64 bit
 *        register regardless the dest is a 32 bits or 64 bits
 *        register
 *
 * --------------------------------------------------------------*/

// Instruction's argument
|.define ARG1_8,                bl
|.define ARG1_16,               bx
|.define ARG1,                  ebx  // must *not* be 64 bits due to we use ah

|.define ARG2_8,                al
|.define ARG2_16,               ax
|.define ARG2,                  eax

|.define ARG3_8,                cl
|.define ARG3_16,               cx
|.define ARG3,                  ecx

// temporary register are r10 and r11
|.define LREG,                  rsi
|.define LREGL,                 esi
|.define RREG,                  rdx
|.define RREGL,                 edx

|.define T1,                    r11
|.define T1L,                   r11d
|.define T2,                    r10
|.define T2L,                   r10d

// registers for normal C function calling ABI
|.define CARG1,                 rdi
|.define CARG2,                 rsi    // LREG
|.define CARG3,                 rdx    // RREG
|.define CARG4,                 rcx
|.define CARG5,                 r8
|.define CARG6,                 r9

|.define CARG1L,                edi
|.define CARG2L,                esi
|.define CARG3L,                edx
|.define CARG4L,                ecx
|.define CARG5L,                r8d
|.define CARG6L,                r9d

|.define CARG1LL,               dil
|.define CARG2LL,               sil
|.define CARG3LL,               dl
|.define CARG4LL,               cl
|.define CARG5LL,               r8b
|.define CARG6LL,               r9b

/* ---------------------------------------------------------------
 * debug helper                                                  |
 * --------------------------------------------------------------*/
|.macro Break
|  int 3
|.endmacro

void PrintOP( int op ) {
  lava_error("OP:%s",GetBytecodeName(static_cast<Bytecode>(op)));
}
INTERPRETER_REGISTER_EXTERN_SYMBOL(PrintOP)

void Print2( int a , int b ) {
  lava_error("L:%d,R:%d",a,b);
}
INTERPRETER_REGISTER_EXTERN_SYMBOL(Print2)

/* ---------------------------------------------------------------
 * dispatch table                                                |
 * --------------------------------------------------------------*/
|.macro Dispatch
|.if 1
|  mov INSTR,dword [PC]
|  movzx T1,INSTR_OP
|  mov CARG1,T1
|  fcall PrintOP
|.endif
|  mov INSTR,dword [PC]
|  movzx T1,INSTR_OP
|  add PC,4
|  jmp aword [DISPATCH+T1*8]
|.endmacro

/* ---------------------------------------------------------------
 * decode each instruction's argument/operand                    |
 * --------------------------------------------------------------*/
|.macro instr_B
|  movzx ARG1,INSTR_A8
|  shr INSTR,16
|.endmacro

|.macro instr_C
|  shr INSTR,8
|  movzx ARG1,INSTR_A16
|  shr INSTR,16
|.endmacro

|.macro instr_D
|  movzx ARG1,INSTR_A8
|  shr INSTR,16
|  movzx ARG3,INSTR_A8
|  or ARG2,0xff
|.endmacro

|.macro instr_E
|  movzx ARG1,INSTR_A8
|  shr INSTR,16
|.endmacro

|.macro instr_F
|  movzx ARG1,INSTR_A8
|.endmacro

|.macro instr_G
|  shr INSTR,8
|  movzx ARG1,INSTR_A16
|.endmacro

|.macro instr_X
|.endmacro

|.macro instr_N
|  instr_D
|.endmacro


/* -----------------------------------------------------------
 * constant loading                                          |
 * ----------------------------------------------------------*/

// Currently our constant loading is *slow* due to the design of our GC
// and also the layout of each constant array. I think we have a way to
// optimize away one memory move. LuaJIT's constant loading is just one
// single instruction since they only get one constant array and they don't
// need to worry about GC move the reference
|.macro LdInt,reg,index
|  mov T1,qword [PROTO]
|  mov T1,qword [T1+PrototypeLayout::kIntTableOffset]
|  mov reg, [T1+index*4]
|.endmacro

// TODO:: Optimize this piece of shit
|.macro LdIntV,reg,regL,index
|  mov T1,qword [PROTO]
|  mov T1,qword [T1+PrototypeLayout::kIntTableOffset]

|.if 1
|  mov reg, Value::FLAG_INTEGER
|  shl reg,32
|  or regL,dword [T1+index*4]
|.else
|  mov64 reg, static_cast<std::uint64_t>(Value::TAG_INTEGER)
|  or regL,dword [T1+index*4]
|.endif

|.endmacro

|.macro LdReal,reg,index
|  mov T1,qword [PROTO]
|  mov T1,qword [T1+PrototypeLayout::kRealTableOffset]
|  movsd reg,qword[T1+index*8]
|.endmacro

|.macro LdRealV,reg,index
|  mov T1,qword [PROTO]
|  mov T1,qword [T1+PrototypeLayout::kRealTableOffset]
// not a xmm register
|  mov reg,qword[T1+index*8]
|.endmacro

|.macro LdInt2Real,reg,index
|  mov T1,qword [PROTO]
|  mov T1,qword [T1+PrototypeLayout::kIntTableOffset]
|  cvtsi2sd reg, dword [T1+index*4]
|.endmacro

|.macro StIntACC,reg
|  mov dword [STK+ACCIDX],reg
|  mov dword [STK+ACCFIDX],Value::FLAG_INTEGER
|.endmacro

|.macro StInt,index,reg
|  mov dword [STK+index*8],reg
|  mov dword [STK+index*8+4],Value::FLAG_INTEGER
|.endmacro

|.macro StRealACC,reg
|  movsd qword [ACC],reg
|.endmacro

|.macro CheckNum,index,val,real_label,int_label
|.if 0
|  cmp dword[STK+index*8+4],Value::FLAG_REAL
|  jb >real_label
|  cmp dword[STK+index*8+4],Value::FLAG_INTEGER
|  je >int_label
|.else
|  mov T1,val
|  shr T1,32
|  cmp T1,Value::FLAG_REAL
|  jb >real_label
|  cmp T1,Value::FLAG_INTEGER
|  je >int_label
|.endif
|.endmacro

// Set a pointer into a register , this is really painful
|.macro StHeap,reg,val

|.if 1
|  mov reg,Value::FLAG_HEAP
|  shl reg,48
|  or reg ,val
|.else
|  mov reg,val
|  or  reg,qword [->ValueHeapStoreMask]
|.endif

|.endmacro

// Store a pointer into memory pointed by index
|.macro StHeapMem,index,ptr
|  mov qword[STK+index*8]  ,ptr
|  mov word [STK+index*8+6],Value::FLAG_HEAP
|.endmacro

// Load a pointer from Value object , assume this object
// is a pointer type
|.macro LdPtrFromV,dest,val
|.if 1
|  mov dest,Value::FLAG_HEAP_UNMASK
|  shl dest,48
|  or  dest,val
|.else
|  mov dest,val
|  or  dest,qword [->ValueHeapLoadMask]
|.endif
|.endmacro

// It is painful to load a string into its Value format
|.macro LdStrV,val,index
|  mov T1 , qword [PROTO]
|  mov T1 , qword [T1+PrototypeLayout::kStrTableOffset]
|  mov T1 , qword [T1+index*8]
|  StHeap val,T1
|.endmacro

|.macro LdStr,val,index
|  mov T1 , qword [PROTO]
|  mov T1 , qword [T1+PrototypeLayout::kStrTableOffset]
|  mov val, qword [T1+index*8]
|.endmacro

#define INTERP_HELPER_LIST(__) \
  /* arithmetic */                           \
  __(INTERP_START,InterpStart)               \
  __(INTERP_FAIL ,InterpFail)                \
  __(INTERP_RETURN,InterpReturn)             \
  __(INTERP_ARITH_INTL,InterpArithIntL)      \
  __(INTERP_ARITH_INTR,InterpArithIntR)      \
  __(INTERP_ARITH_REALL,InterpArithRealL)    \
  __(INTERP_ARITH_REALR,InterpArithRealR)    \
  __(INTERP_ARITH_VV,InterpArithVV)          \
  __(INTERP_POW_FAST,InterpPowFast)          \
  __(INTERP_POW_SLOWVI,InterpPowSlowVI)      \
  __(INTERP_POW_SLOWIV,InterpPowSlowIV)      \
  __(INTERP_POW_SLOWVR,InterpPowSlowVR)      \
  __(INTERP_POW_SLOWRV,InterpPowSlowRV)      \
  __(INTERP_POW_SLOWVV,InterpPowSlowVV)      \
  __(DIV_BY_ZERO,DivByZero)                  \
  __(MOD_BY_REAL,ModByReal)                  \
  /* comparison */                           \
  __(INTERP_COMPARE,InterpDoCompare)           \
  /* ---- debug helper ---- */               \
  __(PRINT_OP,PrintOP)                       \
  __(PRINT2  ,Print2 )

enum {
  INTERP_HELPER_DUMMY = SIZE_OF_BYTECODE,

#define __(A,B) A,
  INTERP_HELPER_LIST(__)
#undef __

  DASM_GROWABLE_PC_SIZE
};

#define INTERP_HELPER_START (INTERP_HELPER_DUMMY+1)
#define INTERP_HELPER_SIZE (DASM_GROWABLE_PC_SIZE-INTERP_HELPER_ROUTINE_ENUM-1)

const char* GetInterpHelperName( int idx ) {
  switch(idx) {
#define __(A,B) case A: return #B;
    INTERP_HELPER_LIST(__)
    default:
      lava_unreachF("unknown helper with index:%d",idx);
      return NULL;
#undef __ // __
  }
}

/* -----------------------------------------------------------
 * Macro Interfaces for Dynasm                               |
 * ----------------------------------------------------------*/
#define Dst (&(bctx->dasm_ctx))

/* -----------------------------------------------------------
 * Interpreter Prolog                                        |
 * ----------------------------------------------------------*/
void GenerateInterpMisc( BuildContext* bctx ) {
  /* -------------------------------------------
   * Constant value needed for the interpreter |
   * ------------------------------------------*/
  |.data
  |->ValueHeapMaskStore:
  |.dword Value::TAG_HEAP_STORE_MASK_HIGHER,Value::TAG_HEAP_STORE_MASK_LOWER

  |->ValueHeapMaskLoad:
  |.dword Value::TAG_HEAP_LOAD_MASK_HIGHER,Value::TAG_HEAP_LOAD_MASK_LOWER

  |.code
  /* -------------------------------------------
   * Start of the code                         |
   * ------------------------------------------*/

  |.macro interp_pushr
  |  push  r12            // runtime
  |  push  r13            // proto
  |  push  r14            // stack
  |  push  r15            // dispatch
  |  push  rbp            // PC
  |  push  rbx            // used by ARG2 , this may be changed in the future
  |.endmacro

  |.macro interp_popr
  |  pop   rbx
  |  pop   rbp
  |  pop   r15
  |  pop   r14
  |  pop   r13
  |  pop   r12
  |.endmacro

  /* -------------------------------------------
   * Interpreter Prolog                        |
   * ------------------------------------------*/
  |=> INTERP_START:
  |->InterpStart:
  // save all callee saved register since we use them to keep tracking of
  // our most important data structure
  |  interp_pushr

  |  mov RUNTIME ,CARG1   // runtime
  |  mov PROTO   ,CARG2   // proto
  |  mov STK     ,CARG3   // stack
  |  mov PC      ,CARG4   // pc
  |  mov DISPATCH,CARG5   // dispatch
  // run
  |  Dispatch

  /* -------------------------------------------
   * Interpreter exit handler                  |
   * ------------------------------------------*/
  |=> INTERP_FAIL:
  |->InterpFail:
  |  xor rax,rax

  |  interp_popr
  |  ret

  |=> INTERP_RETURN:
  |->InterpReturn:
  |  mov rax, qword [ACC]
  |  mov qword [RUNTIME+RuntimeLayout::kRetOffset],rax
  |  mov rax,1

  |  interp_popr
  |  ret
}

/* ------------------------------------------
 * helper functions/routines generation     |
 * -----------------------------------------*/
void GenerateHelper( BuildContext* bctx ) {
  /* ----------------------------------------
   * InterpArithXXX                         |
   * ---------------------------------------*/
  |.macro handle_ret
  |  mov T1,rax
  |  shr T1,32
  |  cmp T1,VALUE_FAIL
  |  je ->InterpFail
  |  mov qword [ACC], rax
  |  Dispatch
  |.endmacro

  |=> INTERP_ARITH_INTL:
  |->InterpArithIntL:
  |  mov CARG1,RUNTIME
  |  LdIntV CARG2,CARG2L,ARG1
  |  movzx CARG4,byte [PC-4]
  |  fcall InterpreterDoArithmetic
  |  handle_ret

  |=> INTERP_ARITH_INTR:
  |->InterpArithIntR:
  |  mov CARG1,RUNTIME
  |  LdIntV CARG3,CARG3L,ARG2
  |  movzx CARG4,byte [PC-4]
  |  fcall InterpreterDoArithmetic
  |  handle_ret

  |=> INTERP_ARITH_REALL:
  |->InterpArithRealL:
  |  mov CARG1,RUNTIME
  |  LdRealV CARG2,ARG1
  |  movzx CARG4,byte [PC-4]
  |  fcall InterpreterDoArithmetic
  |  handle_ret

  |=> INTERP_ARITH_REALR:
  |->InterpArithRealR:
  |  mov CARG1,RUNTIME
  |  LdRealV CARG3,ARG2
  |  movzx CARG4,byte [PC-4]
  |  fcall InterpreterDoArithmetic
  |  handle_ret

  |=> INTERP_ARITH_VV:
  |->InterpArithVV:
  |  mov CARG1, RUNTIME
  |  mov CARG2, qword [STK+ARG1*8]
  |  mov CARG3, qword [STK+ARG2*8]
  |  movzx CARG4,byte [PC-4]
  |  fcall InterpreterDoArithmetic
  |  handle_ret

  |=> INTERP_POW_FAST:
  |->InterpPowFast:
  |  fcall Pow
  |  movsd qword [ACC],xmm0
  |  Dispatch

  |=> INTERP_POW_SLOWIV:
  |->InterpPowSlowIV:
  |  mov CARG1, RUNTIME
  |  LdIntV CARG2,CARG2L,ARG1
  |  mov CARG3,qword [STK+ARG2*8]
  |  movzx CARG4,byte  [PC-4]
  |  fcall InterpreterPow
  |  handle_ret

  |=> INTERP_POW_SLOWRV:
  |->InterpPowSlowRV:
  |  mov CARG1, RUNTIME
  |  LdRealV CARG2,ARG1
  |  mov CARG3,qword [STK+ARG2*8]
  |  movzx CARG4,byte[PC-4]
  |  fcall InterpreterPow
  |  handle_ret

  |=> INTERP_POW_SLOWVI:
  |->InterpPowSlowVI:
  |  mov CARG1, RUNTIME
  |  mov CARG2, qword [STK+ARG1*8]
  |  LdIntV CARG3,CARG3L,ARG2
  |  movzx CARG4, byte [PC-4]
  |  fcall InterpreterPow
  |  handle_ret

  |=> INTERP_POW_SLOWVR:
  |->InterpPowSlowVR:
  |  mov CARG1, RUNTIME
  |  mov CARG2, qword [STK+ARG1*8]
  |  LdRealV CARG3,ARG2
  |  movzx CARG4, byte [PC-4]
  |  fcall InterpreterPow
  |  handle_ret

  |=> INTERP_POW_SLOWVV:
  |->InterpPowSlowVV:
  |  mov CARG1, RUNTIME
  |  mov CARG2,qword [STK+ARG1*8]
  |  LdRealV CARG3,ARG2
  |  movzx CARG4, byte [PC-4]
  |  fcall InterpreterPow
  |  handle_ret

  /* -------------------------------------------
   * Interp Arithmetic Exception               |
   * ------------------------------------------*/
  |=> DIV_BY_ZERO:
  |->DivByZero:
  |  mov CARG1,RUNTIME
  |  lea CARG2,[PC-4]
  |  fcall InterpreterDivByZero
  |  jmp ->InterpFail

  |=> MOD_BY_REAL:
  |->ModByReal:
  |  mov CARG1,RUNTIME
  |  lea CARG2,[PC-4]
  |  fcall InterpreterModByReal
  |  jmp ->InterpFail


  /* -------------------------------------------
   * Interp Comparison                         |
   * ------------------------------------------*/
  |=> INTERP_COMPARE:
  |->InterpDoCompare:
  |  mov CARG1,RUNTIME
  |  fcall InterpreterDoCompare
  |  handle_ret

}

void GenerateOneBytecode( BuildContext* bctx, Bytecode bc ) {
  // hack around idiv operator which are used to implement the
  // BC_MODXX and BC_DIVXX instruction. It has a different format
  // and different result/output
  bool arith_div = false;
  bool arith_mod = false;

  switch(bc) {
    /** =====================================================
     *  Call handling                                       |
     *  ====================================================*/
    case BC_RETNULL:
      |=> bc:
      |  instr_X
      |  mov dword [STK+ACCFIDX],Value::FLAG_NULL
      |  jmp ->InterpReturn
      break;

    case BC_RET:
      |=> bc:
      |  instr_X
      |  jmp ->InterpReturn
      break;

    /** =====================================================
     *  Register Move                                       |
     *  ====================================================*/
    case BC_MOVE:
      |=> bc:
      |  instr_E
      |  mov RREG,qword [STK+ARG2*8]
      |  mov qword [STK+ARG1*8],RREG
      |  Dispatch
      break;
    /** =====================================================
     *  Constant Loading                                    |
     *  ====================================================*/
    case BC_LOADI:
      |=> bc:
      |  instr_B
      |  LdInt LREGL,ARG2
      |  StInt ARG1,LREGL
      |  Dispatch
      break;

    case BC_LOAD0:
      |=> bc:
      |  instr_B
      |  StInt ARG1,0
      |  Dispatch
      break;

    case BC_LOAD1:
      |=> bc:
      |  instr_B
      |  StInt ARG1,1
      |  Dispatch
      break;

    case BC_LOADN1:
      |=> bc:
      |  instr_B
      |  StInt ARG1,-1
      |  Dispatch
      break;

    case BC_LOADR:
      |=> bc:
      |  instr_B
      |  LdReal xmm0,ARG2
      |  movsd qword [STK+ARG1*8],xmm0
      |  Dispatch
      break;

    case BC_LOADNULL:
      |=> bc:
      |  instr_F
      |  mov dword [STK+ARG1*8+4],Value::FLAG_NULL
      |  Dispatch
      break;

    case BC_LOADTRUE:
      |=> bc:
      |  instr_F
      |  mov dword [STK+ARG1*8+4],Value::FLAG_TRUE
      |  Dispatch
      break;

    case BC_LOADFALSE:
      |=> bc:
      |  instr_F
      |  mov dword [STK+ARG1*8+4],Value::FLAG_FALSE
      |  Dispatch
      break;

    /** =====================================================
     *  Arith XV                                            |
     *  ====================================================*/
    |.macro arith_xv_pre,BC,SlowPath
    |  instr_C
    |  mov RREG,qword [STK+ARG2*8]
    |  CheckNum ARG2,RREG,1,2
    |  jmp ->SlowPath
    |.endmacro

    |.macro arith_iv_real,instr
    |  LdInt2Real xmm0,ARG1
    |  movd xmm1,RREG
    |  instr xmm0,xmm1
    |  StRealACC xmm0
    |  Dispatch
    |.endmacro

    |.macro arith_rv_real,instr
    |  LdReal xmm0,ARG1
    |  movd xmm1,RREG
    |  instr xmm0,xmm1
    |  StRealACC xmm0
    |  Dispatch
    |.endmacro

    |.macro arith_iv_do_div
    |  mov T1L,dword [STK+ARG2*8]
    |  LdInt eax,ARG1
    |.if 1
    |  test eax,eax
    |  je ->DivByZero
    |.endif
    |  cdq
    |  idiv T1L
    |.endmacro

    |.macro arith_iv_int,instr
    || if( arith_div ) {
    |    arith_iv_do_div
    |    StIntACC eax
    || } else if( arith_mod ) {
    |    arith_iv_do_div
    |    StIntACC edx
    || } else {
    |    LdInt LREGL,ARG1
    |    instr LREGL,RREGL
    |    StIntACC LREGL
    || }
    |  Dispatch
    |.endmacro

    |.macro arith_rv_int,instr
    |  LdReal xmm0,ARG1
    |  cvtsi2sd xmm1, RREGL
    |  instr xmm0,xmm1
    |  StRealACC xmm0
    |  Dispatch
    |.endmacro

    case BC_ADDIV:
      |=> bc:
      |  arith_xv_pre BC_ADDIV,InterpArithIntL
      |1:
      |  arith_iv_real,addsd
      |2:
      |  arith_iv_int,add
      break;

    case BC_ADDRV:
      |=>bc:
      |  arith_xv_pre BC_ADDRV,InterpArithRealL
      |1:
      |  arith_rv_real,addsd
      |2:
      |  arith_rv_int,addsd
      break;

    case BC_SUBIV:
      |=>bc:
      |  arith_xv_pre BC_SUBIV,InterpArithIntL
      |1:
      |  arith_iv_real,subsd
      |2:
      |  arith_iv_int ,sub
      break;

    case BC_SUBRV:
      |=>bc:
      |  arith_xv_pre BC_SUBRV,InterpArithRealL
      |1:
      |  arith_rv_real,subsd
      |2:
      |  arith_rv_int ,subsd
      break;

    case BC_MULIV:
      |=>bc:
      |  arith_xv_pre BC_MULIV,InterpArithIntL
      |1:
      |  arith_iv_real,mulsd
      |2:
      |  arith_iv_int,imul
      break;

    case BC_MULRV:
      |=>bc:
      |  arith_xv_pre BC_MULRV,InterpArithRealL
      |1:
      |  arith_rv_real,mulsd
      |2:
      |  arith_rv_int,mulsd
      break;

    case BC_DIVIV:
      arith_div = true;
      |=>bc:
      |  arith_xv_pre BC_DIVIV,InterpArithIntL
      |1:
      |  arith_iv_real,mulsd
      |2:
      |  arith_iv_int,imul
      break;

    case BC_DIVRV:
      arith_div = true;
      |=>bc:
      |  arith_xv_pre BC_DIVRV,InterpArithRealL
      |1:
      |  arith_rv_real,divsd
      |2:
      |  arith_rv_int,divsd
      break;

    case BC_MODIV:
      arith_mod = true;
      |=>bc:
      |  arith_xv_pre BC_MODIV,InterpArithIntL
      |1:
      |  jmp ->ModByReal
      |2:
      |  arith_iv_int,imul
      break;

    /* =========================================================
     * Arith VX                                                |
     * ========================================================*/
    |.macro arith_vx_pre,BC,SlowPath
    |  instr_B
    |  mov LREG,qword [STK+ARG1*8]
    |  CheckNum ARG1,LREG,1,2
    |  jmp ->SlowPath
    |.endmacro

    |.macro arith_vi_real,instr
    |  LdInt2Real xmm1,ARG2
    |  movd xmm0,LREG
    |  instr xmm0,xmm1
    |  StRealACC xmm0
    |  Dispatch
    |.endmacro

    |.macro arith_vi_do_div
    |.if 1
    |  test LREGL,LREGL
    |  jmp ->DivByZero
    |.endif
    |  LdInt T1L,ARG2
    |  mov eax,LREGL
    |  cdq
    |  idiv T1L
    |.endmacro

    |.macro arith_vi_int,instr
    || if( arith_div ) {
    |    arith_vi_do_div
    |    StIntACC eax
    || } else if(arith_mod) {
    |    LdInt T1L,ARG2
    |    arith_vi_do_div
    |    StIntACC edx
    || } else {
    |    LdInt RREGL,ARG2
    |    instr LREGL,RREGL
    |    StIntACC LREGL
    || }
    |  Dispatch
    |.endmacro

    |.macro arith_vr_real,instr
    |  LdReal xmm1, ARG2
    |  movd xmm0,LREG
    |  instr xmm0,xmm1
    |  StRealACC xmm0
    |  Dispatch
    |.endmacro

    |.macro arith_vr_int,instr
    |  LdReal xmm1,ARG2
    |  cvtsi2sd xmm0, LREGL
    |  instr xmm0,xmm1
    |  StRealACC xmm0
    |  Dispatch
    |.endmacro

    case BC_ADDVI:
      |=> bc:
      |  arith_vx_pre BC_ADDVI,InterpArithIntR
      |1:
      |  arith_vi_real addsd
      |2:
      |  arith_vi_int  add
      break;

    case BC_ADDVR:
      |=> bc:
      |  arith_vx_pre BC_ADDVR,InterpArithRealR
      |1:
      |  arith_vr_real addsd
      |2:
      |  arith_vr_int addsd
      break;

    case BC_SUBVI:
      |=> bc:
      |  arith_vx_pre BC_SUBVI,InterpArithIntR
      |1:
      |  arith_vi_real subsd
      |2:
      |  arith_vi_int sub
      break;

    case BC_SUBVR:
      |=> bc:
      |  arith_vx_pre BC_SUBVR,InterpArithRealR
      |1:
      |  arith_vr_real subsd
      |2:
      |  arith_vr_int subsd
      break;

    case BC_MULVI:
      |=> bc:
      |  arith_vx_pre BC_MULVI,InterpArithIntR
      |1:
      |  arith_vi_real mulsd
      |2:
      |  arith_vi_int imul
      break;

    case BC_MULVR:
      |=> bc:
      |  arith_vx_pre BC_MULVR,InterpArithRealR
      |1:
      |  arith_vr_real mulsd
      |2:
      |  arith_vr_real mulsd
      break;

    case BC_DIVVI:
      |=> bc:
      arith_div = true;
      |  arith_vx_pre BC_DIVVI,InterpArithIntR
      |1:
      |  arith_vi_real divsd
      |2:
      |  arith_vi_int sub
      break;

    case BC_DIVVR:
      |=> bc:
      |  arith_vx_pre BC_DIVVR,InterpArithRealR
      |1:
      |  arith_vr_real divsd
      |2:
      |  arith_vr_int divsd
      break;

    case BC_MODVI:
      arith_mod = true;
      |=> bc:
      |  arith_vx_pre BC_MODVI,InterpArithIntR
      |1:
      |  jmp ->ModByReal
      |2:
      |  arith_vi_int imul
      break;

    /* ========================================================
     * ArithVV
     *
     * The arithVV is also optimized for common path here.
     * We inline all numeric calculation cases, int/real.
     * Other cases will be pushed back to call C++ function
     * which may be extended to support meta function call
     * ========================================================*/
    |.macro arith_vv_do_div
    |  mov T1L,dword [STK+ARG2*8]
    |  mov eax,dword [STK+ARG1*8]
    |.if 1
    |  test eax,eax
    |  je ->DivByZero
    |.endif
    |  cdq
    |  idiv T1L
    |.endmacro

    // perform VV calaculation based on instruction
    |.macro arith_vv,BC,instrI,setterI,instrR,setterR
    |=> BC:
    |  instr_E
    |  mov LREGL,dword [STK+ARG1*8+4]
    |  mov RREGL,dword [STK+ARG2*8+4]

    // here we will do a type check and also promotion
    |  cmp LREGL,Value::FLAG_INTEGER
    |  je >1
    |  cmp RREGL,Value::FLAG_REAL
    |  jb >2
    |  jmp >6 // cannot handle

    |1:
    |  cmp RREGL,Value::FLAG_INTEGER
    |  je >4 // int && int
    |  cmp RREGL,Value::FLAG_REAL
    |  jnb >6 // cannot handle

    // promoting LHS->real
    |  cvtsi2sd xmm0,dword [STK+ARG1*8]
    |  instrR   xmm0,qword [STK+ARG2*8]
    |  setterR  xmm0
    |  Dispatch

    |2:
    |  cmp RREGL,Value::FLAG_REAL
    |  jb >5  // real && real
    |  cmp RREGL,Value::FLAG_INTEGER
    |  jne >6 // cannot handle

    // promoting RHS->real
    |  cvtsi2sd xmm1,dword [STK+ARG2*8]
    |  movsd    xmm0,qword [STK+ARG1*8]
    |  setterR  xmm0
    |  Dispatch

    // int && int
    |4:
    || if( arith_div ) {
         // order matters
    |    arith_vv_do_div
    |    setterI eax
    || } else if (arith_mod) {
         // order matters
    |    arith_vv_do_div
    |    setterI edx
    || } else {
    |    mov     LREGL,dword [STK+ARG1*8]
    |    instrI  LREGL,dword [STK+ARG2*8]
    |    setterI LREGL
    || }
    |  Dispatch

    // real && real
    |5:
    || if( arith_mod ) {
    |    jmp ->ModByReal
    || } else {
    |    movsd   xmm0,qword [STK+ARG1*8]
    |    instrR  xmm0,qword [STK+ARG2*8]
    |    setterR xmm0
    || }
    |  Dispatch

    // slow path
    |6:
    |  jmp ->InterpArithVV

    |.endmacro

    case BC_ADDVV:
      |  arith_vv BC_ADDVV,add,StIntACC,addsd,StRealACC
      break;
    case BC_SUBVV:
      |  arith_vv BC_SUBVV,sub,StIntACC,subsd,StRealACC
      break;
    case BC_MULVV:
      |  arith_vv BC_MULVV,imul,StIntACC,mulsd,StRealACC
      break;
    case BC_DIVVV:
      arith_div = true;
      |  arith_vv BC_DIVVV,imul,StIntACC,divsd,StRealACC
      break;
    case BC_MODVV:
      arith_mod = true;
      |  arith_vv BC_MODVV,imul,StIntACC,divsd,StRealACC
      break;

    /* ==============================================================
     * POW part
     *
     * Currently we directly use std::pow/pow in libc for simplicity.
     * For numeric type we will directly call pow for other types
     * we will fallback to slow C++ function
     * =============================================================*/

    |.macro pow_promo,REGL,XREG,ARG
    |  mov REGL,dword [STK+ARG*8+4]
    |  cmp REGL,Value::FLAG_REAL
    |  jb >1
    |  cmp REGL,Value::FLAG_INTEGER
    |  jne >2
    |  cvtsi2sd XREG,qword [STK+ARG*8]
    |.endmacro

    case BC_POWIV:
      |=> bc:
      |  instr_C
      |  LdInt2Real,xmm0,ARG1
      |  pow_promo,RREGL,xmm1,ARG2
      |1:
      |  jmp ->InterpPowFast
      |2:
      |  jmp ->InterpPowSlowIV
      break;

    case BC_POWVI:
      |=> bc:
      |  instr_B
      |  LdInt2Real,xmm1,ARG2
      |  pow_promo,LREGL,xmm0,ARG1
      |1:
      |  jmp ->InterpPowFast
      |2:
      |  jmp ->InterpPowSlowVI
      break;

    case BC_POWRV:
      |=> bc:
      |  instr_C
      |  LdReal xmm0,ARG1
      |  pow_promo RREGL,xmm1,ARG2
      |1:
      |  jmp ->InterpPowFast
      |2:
      |  jmp ->InterpPowSlowRV
      break;

    case BC_POWVR:
      |=> bc:
      |  instr_C
      |  LdReal xmm1,ARG2
      |  pow_promo LREGL,xmm0,ARG1
      |1:
      |  jmp ->InterpPowFast
      |2:
      |  jmp ->InterpPowSlowVR
      break;

    case BC_POWVV:
      |=> bc:
      |  instr_C
      |  jmp ->InterpPowSlowVV
      break;


    /* ====================================================================
     * Comparison
     *
     * Inline numeric comparison and also do promotion inline
     * ===================================================================*/

    /* --------------------------------------------------------------------
     *
     * Comparison XV
     *
     * -------------------------------------------------------------------*/
    // pre-phase of each comparison
    |.macro comp_xv_pre,BC,SlowPath,mov_ops
    |  instr_C
    |  mov RREG,qword [STK+ARG2*8]
    |  CheckNum ARG2,RREG,1,2
    |  mov_ops
    |  mov CARG4,BC    // Always mov CARG4 at last since it alias with ARG3
    |  jmp ->SlowPath
    |.endmacro

    // comparison phase , we have 2 versions , need to profile
    |.macro comp_cmp_real,instr
    |  mov T1L, Value::FLAG_FALSE
    |  mov T2L, Value::FLAG_TRUE
    |  ucomisd xmm0,xmm1
    |  instr T1L, T2L
    |  mov dword [STK+ACCFIDX], T1L
    |.endmacro

    |.macro comp_cmp_int,instr
    |  mov T1L, Value::FLAG_FALSE
    |  mov T2L, Value::FLAG_TRUE
    |  cmp LREGL,RREGL
    |  instr T1L, T2L
    |  mov dword [STK+ACCFIDX], T1L
    |.endmacro

    // real/int part for iv/rv
    |.macro comp_iv_real,instr
    |  LdInt2Real xmm0,ARG1
    |  movd xmm1,RREG
    |  comp_cmp_real,instr
    |  Dispatch
    |.endmacro

    |.macro comp_iv_int,instr
    |  LdInt LREGL,ARG1
    |  comp_cmp_int,instr
    |  Dispatch
    |.endmacro

    |.macro comp_rv_real,instr
    |  LdReal xmm0,ARG1
    |  movsd xmm1,qword [STK+ARG2*8]
    |  comp_cmp_real,instr
    |  Dispatch
    |.endmacro

    |.macro comp_rv_int,instr
    |  LdReal xmm0,ARG1
    |  cvtsi2sd xmm1,dword [STK+ARG2*8]
    |  comp_cmp_real,instr
    |  Dispatch
    |.endmacro

    |.macro comp_xv_mov_iv_ops
    |  LdIntV CARG2,CARG2L,ARG1
    |  mov CARG3,RREG
    |.endmacro

    |.macro comp_xv_mov_rv_ops
    |  LdRealV CARG2,ARG1
    |  mov CARG3,RREG
    |.endmacro

    case BC_LTIV:
      |=> bc:
      |  comp_xv_pre,BC_LTIV,InterpDoCompare,comp_xv_mov_iv_ops
      |1:
      |  comp_iv_real,cmovl
      |2:
      |  comp_iv_int,cmovl
      break;
    case BC_LTRV:
      |=>bc:
      |  comp_xv_pre,BC_LTRV,InterpDoCompare,comp_xv_mov_rv_ops
      |1:
      |  comp_rv_real,cmovl
      |2:
      |  comp_rv_int,cmovl
      break;
    case BC_LEIV:
      |=> bc:
      |  comp_xv_pre,BC_LEIV,InterpDoCompare,comp_xv_mov_iv_ops
      |1:
      |  comp_iv_real,cmovle
      |2:
      |  comp_iv_int,cmovle
      break;
    case BC_LERV:
      |=> bc:
      |  comp_xv_pre,BC_LERV,InterpDoCompare,comp_xv_mov_rv_ops
      |1:
      |  comp_rv_real,cmovle
      |2:
      |  comp_rv_int,cmovle
      break;
    case BC_GTIV:
      |=> bc:
      |  comp_xv_pre,BC_GTIV,InterpDoCompare,comp_xv_mov_iv_ops
      |1:
      |  comp_iv_real,cmovg
      |2:
      |  comp_iv_int,cmovg
      break;
    case BC_GTRV:
      |=>bc:
      |  comp_xv_pre,BC_GTRV,InterpDoCompare,comp_xv_mov_rv_ops
      |1:
      |  comp_rv_real,cmovg
      |2:
      |  comp_rv_int ,cmovg
      break;
    case BC_GEIV:
      |=> bc:
      |  comp_xv_pre,BC_GEIV,InterpDoCompare,comp_xv_mov_iv_ops
      |1:
      |  comp_iv_real,cmovge
      |2:
      |  comp_iv_int,cmovge
      break;
    case BC_GERV:
      |=> bc:
      |  comp_xv_pre,BC_GERV,InterpDoCompare,comp_xv_mov_rv_ops
      |1:
      |  comp_rv_real ,cmovge
      |2:
      |  comp_rv_int  ,cmovge
      break;
    case BC_EQIV:
      |=> bc:
      |  comp_xv_pre,BC_EQIV,InterpDoCompare,comp_xv_mov_iv_ops
      |1:
      |  comp_iv_real,cmove
      |2:
      |  comp_iv_int,cmove
      break;
    case BC_EQRV:
      |=> bc:
      |  comp_xv_pre,BC_EQRV,InterpDoCompare,comp_xv_mov_rv_ops
      |1:
      |  comp_rv_real,cmove
      |2:
      |  comp_rv_int,cmove
      break;
    case BC_NEIV:
      |=> bc:
      |  comp_xv_pre,BC_NEIV,InterpDoCompare,comp_xv_mov_iv_ops
      |1:
      |  comp_iv_real,cmovne
      |2:
      |  comp_iv_int,cmovne
      break;
    case BC_NERV:
      |=> bc:
      |  comp_xv_pre,BC_NERV,InterpDoCompare,comp_xv_mov_rv_ops
      |1:
      |  comp_rv_real,cmovne
      |2:
      |  comp_rv_int,cmovne
      break;

    /* --------------------------------------------------------------------
     *
     * Comparison VX
     *
     * -------------------------------------------------------------------*/
    |.macro comp_vx_pre,BC,SlowPath,mov_ops
    |  instr_C
    |  mov LREG,qword [STK+ARG1*8]
    |  CheckNum ARG1,LREG,1,2
    |  mov_ops
    |  mov CARG4,BC    // Always mov CARG4 at last since it alias with ARG3
    |  jmp ->SlowPath
    |.endmacro

    // real/int part for iv/rv
    |.macro comp_vi_real,instr
    |  LdInt2Real xmm1,ARG2
    |  movd xmm0,LREG
    |  comp_cmp_real,instr
    |  Dispatch
    |.endmacro

    |.macro comp_vi_int,instr
    |  LdInt RREGL,ARG2
    |  comp_cmp_int,instr
    |  Dispatch
    |.endmacro

    |.macro comp_vr_real,instr
    |  LdReal xmm1,ARG2
    |  movsd xmm0, qword [STK+ARG1*8]
    |  comp_cmp_real,instr
    |  Dispatch
    |.endmacro

    |.macro comp_vr_int,instr
    |  LdReal xmm1,ARG2
    |  cvtsi2sd xmm0,dword [STK+ARG1*8]
    |  comp_cmp_real,instr
    |  Dispatch
    |.endmacro

    |.macro comp_vx_mov_vi_ops
    |  mov CARG2,LREG
    |  LdIntV CARG3,CARG3L,ARG2
    |.endmacro

    |.macro comp_vx_mov_vr_ops
    |  mov CARG2,LREG
    |  LdRealV CARG3,ARG2
    |.endmacro

    case BC_LTVI:
      |=>bc:
      |  comp_vx_pre,BC_LTVI,InterpDoCompare,comp_vx_mov_vi_ops
      |1:
      |  comp_vi_real,cmovl
      |2:
      |  comp_vi_int,cmovl
      break;
    case BC_LTVR:
      |=>bc:
      |  comp_vx_pre,BC_LTVR,InterpDoCompare,comp_vx_mov_vr_ops
      |1:
      |  comp_vr_real,cmovl
      |2:
      |  comp_vr_int ,cmovl
      break;
    case BC_LEVI:
      |=>bc:
      |  comp_vx_pre,BC_LEVI,InterpDoCompare,comp_vx_mov_vi_ops
      |1:
      |  comp_vi_real,cmovle
      |2:
      |  comp_vi_int ,cmovle
      break;
    case BC_LEVR:
      |=>bc:
      |  comp_vx_pre,BC_LEVR,InterpDoCompare,comp_vx_mov_vr_ops
      |1:
      |  comp_vr_real,cmovle
      |2:
      |  comp_vr_int ,cmovle
      break;
    case BC_GTVI:
      |=>bc:
      |  comp_vx_pre,BC_GTVI,InterpDoCompare,comp_vx_mov_vi_ops
      |1:
      |  comp_vi_real,cmovg
      |2:
      |  comp_vi_int ,cmovg
      break;
    case BC_GTVR:
      |=>bc:
      |  comp_vx_pre,BC_GTVR,InterpDoCompare,comp_vx_mov_vr_ops
      |1:
      |  comp_vr_real, cmovg
      |2:
      |  comp_vr_int , cmovg
      break;
    case BC_GEVI:
      |=>bc:
      |  comp_vx_pre,BC_GEVI,InterpDoCompare,comp_vx_mov_vi_ops
      |1:
      |  comp_vi_real ,cmovge
      |2:
      |  comp_vi_int  ,cmovge
      break;
    case BC_GEVR:
      |=>bc:
      |  comp_vx_pre,BC_GEVR,InterpDoCompare,comp_vx_mov_vr_ops
      |1:
      |  comp_vr_real ,cmovge
      |2:
      |  comp_vr_int  ,cmovge
      break;
    case BC_EQVI:
      |=>bc:
      |  comp_vx_pre,BC_EQVI,InterpDoCompare,comp_vx_mov_vi_ops
      |1:
      |  comp_vi_real ,cmove
      |2:
      |  comp_vi_int  ,cmove
      break;
    case BC_EQVR:
      |=>bc:
      |  comp_vx_pre,BC_EQVR,InterpDoCompare,comp_vx_mov_vr_ops
      |1:
      |  comp_vr_real ,cmove
      |2:
      |  comp_vr_int  ,cmove
      break;
    case BC_NEVI:
      |=>bc:
      |  comp_vx_pre,BC_NEVI,InterpDoCompare,comp_vx_mov_vi_ops
      |1:
      |  comp_vi_real ,cmovne
      |2:
      |  comp_vi_int  ,cmovne
      break;
    case BC_NEVR:
      |=>bc:
      |  comp_vx_pre,BC_NEVR,InterpDoCompare,comp_vx_mov_vr_ops
      |1:
      |  comp_vr_real ,cmovne
      |2:
      |  comp_vr_int  ,cmovne
      break;

    default:
      |=> bc:
      |  Break
      break;
  }
}

// Help Dasm to resolve external address via Index idx
int ResolveExternAddress( void** ctx , unsigned char* addr ,
                                       int idx,
                                       int type ) {
  (void)ctx;

  ExternSymbolTable* t = GetExternSymbolTable();
  ExternSymbolTable::iterator itr = t->find(extnames[idx]);
  lava_verify( itr != t->end() );

  void* ptr = itr->second;
  lava_verify(CheckAddress(reinterpret_cast<std::uintptr_t>(ptr)));

  int iptr = HorribleCast(ptr);
  lava_verify(reinterpret_cast<void*>(iptr) == ptr);

  if(type) {
    int end = HorribleCast(addr+4);

    // Check whether the address is overflowed or not. I think this is
    // not needed but just in cases we have a bug so we don't end up
    // calling into some wired places into our code
    std::int64_t ptr64 = static_cast<std::int64_t>(iptr);
    std::int64_t end64 = static_cast<std::int64_t>(end);

    lava_verify( (ptr64-end64) >= std::numeric_limits<int>::min() &&
                 (ptr64-end64) <= std::numeric_limits<int>::max() );

    return iptr - HorribleCast(addr+4);
  } else {
    return iptr;
  }
}

} // namespace

AssemblyInterpreter::AssemblyInterpreter():
  dispatch_interp_(),
  dispatch_record_(),
  dispatch_jit_   (),
  interp_helper_  (),
  interp_entry_   (),
  code_size_      (),
  buffer_size_    ()
{}

AssemblyInterpreter::~AssemblyInterpreter() {
  if(interp_entry_) OS::FreeCodePage(interp_entry_,buffer_size_);
}

std::shared_ptr<AssemblyInterpreter> AssemblyInterpreter::Generate() {
  std::shared_ptr<AssemblyInterpreter> interp( new AssemblyInterpreter() );

  // create a build context
  BuildContext bctx;

  // initialize dasm_State object
  dasm_init(&(bctx.dasm_ctx),2);

  // setup the freaking global
  void* glb_arr[GLBNAME__MAX];
  dasm_setupglobal(&(bctx.dasm_ctx),glb_arr,GLBNAME__MAX);

  // setup the dasm
  dasm_setup(&(bctx.dasm_ctx),actions);

  // initialize the tag value needed , at least for each BC we need one
  bctx.tag = DASM_GROWABLE_PC_SIZE;
  dasm_growpc(&(bctx.dasm_ctx), DASM_GROWABLE_PC_SIZE );

  // build the prolog
  GenerateInterpMisc(&bctx);

  // build the helper
  GenerateHelper(&bctx);

  // generate all bytecode's routine
  for( int i = static_cast<int>(BC_ADDIV) ; i < SIZE_OF_BYTECODE ; ++i ) {
    GenerateOneBytecode(&bctx,static_cast<Bytecode>(i));
  }

  std::size_t code_size;

  // we should never fail at *linking* if our code is *correct*
  lava_verify(dasm_link(&(bctx.dasm_ctx),&code_size) ==0);

  // generate a buffer and set the proper protection field for that piece of
  // memory to make our code *work*
  std::size_t new_size;

  void* buffer = OS::CreateCodePage(code_size,&new_size);
  if(!buffer) {
    return std::shared_ptr<AssemblyInterpreter>();
  }

  // encode the assembly code into the buffer
  dasm_encode(&(bctx.dasm_ctx),buffer);

  // get all pc labels for entry of bytecode routine
  for( int i = static_cast<int>(BC_ADDIV) ; i < SIZE_OF_BYTECODE ; ++i ) {
    int off = dasm_getpclabel(&(bctx.dasm_ctx),i);
    interp->dispatch_interp_[i] =
      reinterpret_cast<void*>(static_cast<char*>(buffer) + off);
  }

  // get all pc labels for helper routines
  for( int i = INTERP_HELPER_START ; i < DASM_GROWABLE_PC_SIZE ; ++i ) {
    int off = dasm_getpclabel(&(bctx.dasm_ctx),i);
    interp->interp_helper_.push_back(
        reinterpret_cast<void*>(static_cast<char*>(buffer)+off));
  }

  interp->interp_entry_ = buffer;
  interp->buffer_size_  = new_size;
  interp->code_size_    = code_size;
  return interp;
}

Bytecode AssemblyInterpreter::CheckBytecodeRoutine( void* pc ) const {
  for( int i = 0 ; i < SIZE_OF_BYTECODE ; ++i ) {
    void* p = reinterpret_cast<void*>(pc);
    if(p == dispatch_interp_[i]) {
      return static_cast<Bytecode>(i);
    }
  }
  return SIZE_OF_BYTECODE;
}

int AssemblyInterpreter::CheckHelperRoutine( void* pc ) const {
  std::vector<void*>::const_iterator itr =
    std::find( interp_helper_.begin() , interp_helper_.end() , pc );
  if(itr != interp_helper_.end()) {
    return (static_cast<int>(std::distance(interp_helper_.begin(),itr))+INTERP_HELPER_START);
  } else {
    return -1;
  }
}

void AssemblyInterpreter::Dump( DumpWriter* writer ) const {
  ZydisDecoder decoder;
  ZydisDecoderInit(
      &decoder,
      ZYDIS_MACHINE_MODE_LONG_64,
      ZYDIS_ADDRESS_WIDTH_64);

  ZydisFormatter formatter;
  ZydisFormatterInit(&formatter,ZYDIS_FORMATTER_STYLE_INTEL);

  std::uint64_t pc = reinterpret_cast<std::uint64_t>(interp_entry_);
  std::uint8_t* rp = static_cast<std::uint8_t*>(interp_entry_);
  std::size_t size = code_size_;

  ZydisDecodedInstruction instr;
  while(ZYDIS_SUCCESS(
        ZydisDecoderDecodeBuffer(&decoder,rp,size,pc,&instr))) {

    char buffer[256];
    ZydisFormatterFormatInstruction(
        &formatter,&instr,buffer,sizeof(buffer));
    // check labels
    {
      Bytecode bc = CheckBytecodeRoutine(reinterpret_cast<void*>(pc));
      if(bc != SIZE_OF_BYTECODE) {
        writer->WriteL("Bytecode ===========> %s:",GetBytecodeName(bc));
      } else {
        int idx = CheckHelperRoutine(reinterpret_cast<void*>(pc));
        if(idx >= 0) {
          writer->WriteL("Helper ===========> %s:",GetInterpHelperName(idx));
        }
      }
    }
    writer->WriteL("%016" PRIX64 " (%d) %s",pc,instr.length,buffer);
    rp += instr.length;
    size -= instr.length;
    pc += instr.length;
  }
}

AssemblyInterpreter::Instance::Instance( const std::shared_ptr<AssemblyInterpreter>& interp ):
  dispatch_interp_(),
  dispatch_record_(),
  dispatch_jit_   (),
  interp_         (interp)
{
  memcpy(dispatch_interp_,interp->dispatch_interp_,sizeof(dispatch_interp_));
  memcpy(dispatch_record_,interp->dispatch_record_,sizeof(dispatch_record_));
  memcpy(dispatch_jit_   ,interp->dispatch_jit_   ,sizeof(dispatch_jit_   ));
}

bool AssemblyInterpreter::Instance::Run( Context* context , const Handle<Script>& script ,
                                                           const Handle<Object>& globals,
                                                           std::string* error,
                                                           Value* rval ) {
  Runtime runtime(script,globals,error);
  Main m = reinterpret_cast<Main>(interp_->interp_entry_);
  bool ret = m(&runtime,runtime.cur,reinterpret_cast<void*>(runtime.stack),
                                    const_cast<void*>(
                                      reinterpret_cast<const void*>((*runtime.cur)->code_buffer())),
                                    dispatch_interp_);
  if(ret) {
    *rval = runtime.ret;
  }
  return ret;
}

} // namespace lavascript
} // namespace interpreter
